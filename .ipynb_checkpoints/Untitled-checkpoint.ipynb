{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np \n",
    "from numpy import zeros\n",
    "import pandas as pd \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, Flatten\n",
    "from keras.layers import Input, Embedding, Dense, Conv1D, MaxPool1D, concatenate,MaxPooling2D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.regularizers import L1L2\n",
    "from keras.utils import normalize\n",
    "from sklearn import preprocessing\n",
    "from dataset import dtoc\n",
    "from keras.callbacks import TensorBoard\n",
    "import mlflow\n",
    "from mlflow import log_metric\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "import diag2vec\n",
    "import _pickle as pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "\n",
    "def build_model(model_type, dim, emb_dim):\n",
    "    if model_type == \"LSTM\":\n",
    "        return model_LSTM(dim, emb_dim)\n",
    "    elif model_type == \"LSTM_ATTENTION\":\n",
    "        return model_LSTM_ATTENTION()\n",
    "    elif model_type == \"CNN\":\n",
    "        return model_CNN(dim, emb_dim)\n",
    "    elif model_type == \"LR\":\n",
    "        return model_LR()\n",
    "    else:\n",
    "        raise NameError('Model name not defined')\n",
    "\n",
    "def model_LSTM_ATTENTION():\n",
    "    maxlen = 13\n",
    "    inp = Input(shape=(maxlen,150,))\n",
    "    x = LSTM(128, return_sequences=True)(inp)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    \n",
    "    x = Attention(maxlen)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    \n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def model_LSTM(dim, emb_dim):\n",
    "  \n",
    "\n",
    "    inp = Input(shape=(dim,emb_dim,))\n",
    "    x = LSTM(128, return_sequences=True)(inp)\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    \n",
    "    # x = Attention(maxlen)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    \n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def model_CNN(dim, emb_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, 3,\n",
    "                 activation='relu',\n",
    "                 input_shape=(dim, emb_dim)))\n",
    "    model.add(Conv1D(64, 3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5)) ## To be discussed\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def model_LR():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,  # output dim is 2, one score per each class\n",
    "                # kernel_regularizer=L1L2(l1=0.0, l2=0.1),\n",
    "                activation='sigmoid')) # input dimension = number of features your data h              \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "            lw=1.0, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=1.0, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def run_model(model, train_X, train_y, val_X, val_y, bsize, eps, pred_threhold):\n",
    "\n",
    "    tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    model.fit(train_X, train_y, batch_size=bsize, epochs=eps, validation_data = (val_X, val_y), callbacks=[tbCallBack])\n",
    "\n",
    "    predict_val_origin_y = model.predict(val_X, batch_size=bsize, verbose=1)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(val_y, predict_val_origin_y, pos_label=1)\n",
    "    print('fpr:', fpr)\n",
    "    print('tpr', tpr)\n",
    "    print('thresholds:',thresholds)\n",
    "    plot_roc(fpr, tpr)\n",
    "    \n",
    "    acc = accuracy_score(val_y, predict_val_y)\n",
    "    recall = recall_score(val_y, predict_val_y)\n",
    "    f1 = metrics.f1_score(val_y, predict_val_y)\n",
    "    roc_auc = metrics.roc_auc_score(val_y, predict_val_y)\n",
    "\n",
    "    print(\"Classification report:\\n%s\\n\"\n",
    "      % (metrics.classification_report(val_y, predict_val_y)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(val_y, predict_val_y))\n",
    "\n",
    "    return acc,recall,f1, roc_auc\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_type\", help=\"Choose from LSTM,LSTM_ATTENTION, CNN, LR\", action = 'store', default=\"CNN\", type = str)\n",
    "    parser.add_argument(\"--pred_threhold\", help=\"Prediction threhold\", nargs='?', action='store', default=0.7, type=float)\n",
    "    parser.add_argument(\"--input_dim\", help=\"Input dimension for the network.\", action='store', nargs='?', default=20, type=int)\n",
    "    parser.add_argument(\"--bs\", help=\"Number of rows or size of the tensor\", action='store', nargs='?', default=1000, type=int)\n",
    "    parser.add_argument(\"--output\", help=\"Output from First & Hidden Layers\", action='store',  nargs='?', default=64, type=int)\n",
    "    parser.add_argument(\"--train_batch_size\", help=\"Training Batch Size\", nargs='?', action='store', default=1024, type=int)\n",
    "    parser.add_argument(\"--epochs\", help=\"Number of epochs for training\", nargs='?', action='store', default=20, type=int)\n",
    "    parser.add_argument(\"--embed_model\", help=\"the embedding model used, 0 for cbow, 1 for skip-gram\", nargs='?', action='store', default=1, type=int)\n",
    "    parser.add_argument(\"--emb_dim\", help=\"Embedding dimension\", nargs='?', action='store', default=100, type=int)\n",
    "    parser.add_argument(\"--emb_type\", help=\"signle-embedding(s) or meta-embedding(m)\", nargs='?', action='store', default='m', type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    input_dim = args.input_dim\n",
    "    bs = args.bs\n",
    "    output = args.output\n",
    "    epochs = args.epochs\n",
    "    batch_size = args.train_batch_size\n",
    "    embed_model = args.embed_model\n",
    "    model_type = args.model_type\n",
    "    embed_dim = args.emb_dim\n",
    "    emb_type = args.emb_type\n",
    "    pred_threhold = args.pred_threhold\n",
    "\n",
    "    print(\"model_type\", model_type)\n",
    "    print(\"pred_threthold\", pred_threhold)\n",
    "    print(\"embedding_model\", embed_model)\n",
    "    print(\"embedding_dimension\", embed_dim)\n",
    "    print(\"train_batch_size\", batch_size)\n",
    "    print(\"epochs\", epochs)\n",
    "    print('emb_type:', emb_type)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with mlflow.start_run():\n",
    "        dtoc_X_emb = pickle.load(open(\"dataset/embeds/dtoc_X_emb_22_\" + str(embed_model)+\"_\"+str(embed_dim)+\"_\"+str(emb_type)+\".pkl\", 'rb'))\n",
    "        dtoc_y_emb = pickle.load(open('dataset/embeds/dtoc_y_emb_22_' + str(embed_model)+\"_\"+str(embed_dim)+\"_\"+str(emb_type)+\".pkl\", 'rb'))\n",
    "        train_X,validate_X,train_y, validate_y= train_test_split(dtoc_X_emb, dtoc_y_emb, test_size=0.08, random_state=2018)\n",
    " \n",
    "        input_dim = train_X.shape[1]\n",
    "        input_emb_dim = train_X.shape[2]\n",
    "        model = build_model(model_type, input_dim, input_emb_dim)\n",
    "\n",
    "        acc,recall,f1, roc_auc= run_model(model,train_X,train_y,validate_X,validate_y,batch_size,epochs, pred_threhold)\n",
    "\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        mlflow.log_param(\"pred_threhold\", pred_threhold)\n",
    "        mlflow.log_param(\"embedding_model\", embed_model)\n",
    "        mlflow.log_param(\"embedding_type\", emb_type)\n",
    "        mlflow.log_param(\"input_dim\", input_dim)\n",
    "        mlflow.log_param(\"input_emb_dim\", input_emb_dim)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_metric(\"acc\", acc)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "    timed = time.time() - start_time\n",
    "    print(\"This model took\", timed, \"seconds to train and test.\")\n",
    "    log_metric(\"Time to run\", timed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
