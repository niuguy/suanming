{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/59/d88fe8c58ffb66aca21d03c0e290cd68327cc133591130c674985e98a482/tensorflow-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "Collecting mock>=2.0.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/69/46/ebd21ce467ab87f2cf825413273936f9b1ee0e6cd4e2f2ee62e0516c771f/grpcio-1.25.0-cp27-cp27mu-manylinux1_x86_64.whl (2.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.5MB 409kB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl\n",
      "Collecting enum34>=1.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/68/eed71ec8e8383a43987e0a58492b0aa043dc29971cac59b8b1d1e7951123/google_pasta-0.1.8-py2-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 13.2MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting wheel (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/49/ffa7ab9c52ec56b535cffec3bc844254c073888e6d4aeee464671ac97480/protobuf-3.10.0-cp27-cp27mu-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 1.2MB/s \n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 13.2MB/s \n",
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 541kB/s \n",
      "\u001b[?25hCollecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\" (from grpcio>=1.8.6->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 4.8MB/s \n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/de/554b6310ac87c5b921bc45634b07b11394fe63bc4cb5176f5240addf18ab/setuptools-41.6.0-py2.py3-none-any.whl (582kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 2.6MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: gast, absl-py\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "Successfully built gast absl-py\n",
      "Installing collected packages: numpy, six, h5py, keras-applications, funcsigs, mock, futures, enum34, grpcio, termcolor, setuptools, protobuf, wheel, absl-py, werkzeug, markdown, tensorboard, google-pasta, tensorflow-estimator, astor, backports.weakref, gast, keras-preprocessing, wrapt, tensorflow\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 backports.weakref-1.0.post1 enum34-1.1.6 funcsigs-1.0.2 futures-3.3.0 gast-0.3.2 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 mock-3.0.5 numpy-1.16.5 protobuf-3.10.0 setuptools-41.6.0 six-1.13.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import numpy as np\n",
    "import data_util\n",
    "from model_components import task_specific_attention, bidirectional_rnn\n",
    "import pandas as pd\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HANClassifierModel():\n",
    "  \"\"\" Implementation of document classification model described in\n",
    "    `Hierarchical Attention Networks for Document Classification (Yang et al., 2016)`\n",
    "    (https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf)\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               embedding_size,\n",
    "               classes,\n",
    "               word_cell,\n",
    "               sentence_cell,\n",
    "               word_output_size,\n",
    "               sentence_output_size,\n",
    "               max_grad_norm,\n",
    "               dropout_keep_proba,\n",
    "               is_training=None,\n",
    "               learning_rate=1e-4,\n",
    "               device='/cpu:0',\n",
    "               scope=None):\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embedding_size = embedding_size\n",
    "    self.classes = classes\n",
    "    self.word_cell = word_cell\n",
    "    self.word_output_size = word_output_size\n",
    "    self.sentence_cell = sentence_cell\n",
    "    self.sentence_output_size = sentence_output_size\n",
    "    self.max_grad_norm = max_grad_norm\n",
    "    self.dropout_keep_proba = dropout_keep_proba\n",
    "\n",
    "    with tf.variable_scope(scope or 'tcm') as scope:\n",
    "      self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "      if is_training is not None:\n",
    "        self.is_training = is_training\n",
    "      else:\n",
    "        self.is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "\n",
    "      self.sample_weights = tf.placeholder(shape=(None,), dtype=tf.float32, name='sample_weights')\n",
    "\n",
    "      # [document x sentence x word]\n",
    "      self.inputs = tf.placeholder(shape=(None, None, None), dtype=tf.int32, name='inputs')\n",
    "\n",
    "      # [document x sentence]\n",
    "      self.word_lengths = tf.placeholder(shape=(None, None), dtype=tf.int32, name='word_lengths')\n",
    "\n",
    "      # [document]\n",
    "      self.sentence_lengths = tf.placeholder(shape=(None,), dtype=tf.int32, name='sentence_lengths')\n",
    "\n",
    "      # [document]\n",
    "      self.labels = tf.placeholder(shape=(None,), dtype=tf.int32, name='labels')\n",
    "\n",
    "      (self.document_size,\n",
    "        self.sentence_size,\n",
    "        self.word_size) = tf.unstack(tf.shape(self.inputs))\n",
    "\n",
    "      self._init_embedding(scope)\n",
    "\n",
    "      # embeddings cannot be placed on GPU\n",
    "      with tf.device(device):\n",
    "        self._init_body(scope)\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "      self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.labels, logits=self.logits)\n",
    "\n",
    "#       self.loss = tf.reduce_mean(tf.multiply(self.cross_entropy, self.sample_weights))\n",
    "        \n",
    "        self.loss = tf.reduce_mean(self.cross_entropy)\n",
    "\n",
    "      tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "      self.accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(self.logits, self.labels, 1), tf.float32))\n",
    "      tf.summary.scalar('accuracy', self.accuracy)\n",
    "\n",
    "      tvars = tf.trainable_variables()\n",
    "\n",
    "      grads, global_norm = tf.clip_by_global_norm(\n",
    "        tf.gradients(self.loss, tvars),\n",
    "        self.max_grad_norm)\n",
    "      tf.summary.scalar('global_grad_norm', global_norm)\n",
    "\n",
    "      opt = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "      self.train_op = opt.apply_gradients(\n",
    "        zip(grads, tvars), name='train_op',\n",
    "        global_step=self.global_step)\n",
    "\n",
    "      self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "  def _init_embedding(self, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "      with tf.variable_scope(\"embedding\") as scope:\n",
    "        self.embedding_matrix = tf.get_variable(\n",
    "          name=\"embedding_matrix\",\n",
    "          shape=[self.vocab_size, self.embedding_size],\n",
    "          initializer=layers.xavier_initializer(),\n",
    "          dtype=tf.float32)\n",
    "        self.inputs_embedded = tf.nn.embedding_lookup(\n",
    "          self.embedding_matrix, self.inputs)\n",
    "\n",
    "  def _init_body(self, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "\n",
    "      word_level_inputs = tf.reshape(self.inputs_embedded, [\n",
    "        self.document_size * self.sentence_size,\n",
    "        self.word_size,\n",
    "        self.embedding_size\n",
    "      ])\n",
    "      word_level_lengths = tf.reshape(\n",
    "        self.word_lengths, [self.document_size * self.sentence_size])\n",
    "\n",
    "      with tf.variable_scope('word') as scope:\n",
    "        word_encoder_output, _ = bidirectional_rnn(\n",
    "          self.word_cell, self.word_cell,\n",
    "          word_level_inputs, word_level_lengths,\n",
    "          scope=scope)\n",
    "\n",
    "        with tf.variable_scope('attention') as scope:\n",
    "          word_level_output = task_specific_attention(\n",
    "            word_encoder_output,\n",
    "            self.word_output_size,\n",
    "            scope=scope)\n",
    "\n",
    "        with tf.variable_scope('dropout'):\n",
    "          word_level_output = layers.dropout(\n",
    "            word_level_output, keep_prob=self.dropout_keep_proba,\n",
    "            is_training=self.is_training,\n",
    "          )\n",
    "\n",
    "      # sentence_level\n",
    "\n",
    "      sentence_inputs = tf.reshape(\n",
    "        word_level_output, [self.document_size, self.sentence_size, self.word_output_size])\n",
    "\n",
    "      with tf.variable_scope('sentence') as scope:\n",
    "        sentence_encoder_output, _ = bidirectional_rnn(\n",
    "          self.sentence_cell, self.sentence_cell, sentence_inputs, self.sentence_lengths, scope=scope)\n",
    "\n",
    "        with tf.variable_scope('attention') as scope:\n",
    "          sentence_level_output = task_specific_attention(\n",
    "            sentence_encoder_output, self.sentence_output_size, scope=scope)\n",
    "\n",
    "        with tf.variable_scope('dropout'):\n",
    "          sentence_level_output = layers.dropout(\n",
    "            sentence_level_output, keep_prob=self.dropout_keep_proba,\n",
    "            is_training=self.is_training,\n",
    "          )\n",
    "\n",
    "      with tf.variable_scope('classifier'):\n",
    "        self.logits = layers.fully_connected(\n",
    "          sentence_level_output, self.classes, activation_fn=None)\n",
    "\n",
    "        self.prediction = tf.argmax(self.logits, axis=-1)\n",
    "\n",
    "  def get_feed_data(self, x, y=None, class_weights=None, is_training=True):\n",
    "    x_m, doc_sizes, sent_sizes = data_util.batch(x)\n",
    "    fd = {\n",
    "      self.inputs: x_m,\n",
    "      self.sentence_lengths: doc_sizes,\n",
    "      self.word_lengths: sent_sizes,\n",
    "    }\n",
    "    if y is not None:\n",
    "      fd[self.labels] = y\n",
    "      if class_weights is not None:\n",
    "        fd[self.sample_weights] = [class_weights[yy] for yy in y]\n",
    "      else:\n",
    "        fd[self.sample_weights] = np.ones(shape=[len(x_m)], dtype=np.float32)\n",
    "    fd[self.is_training] = is_training\n",
    "    return fd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1120 11:14:42.644718 139884432922368 deprecation.py:323] From <ipython-input-15-8a4adaf5482d>:14: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W1120 11:14:42.702596 139884432922368 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W1120 11:14:42.790794 139884432922368 deprecation.py:323] From /home/jupyter/work/suanming/notebooks/model_components.py:24: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W1120 11:14:42.791736 139884432922368 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W1120 11:14:43.017456 139884432922368 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W1120 11:14:43.414625 139884432922368 deprecation.py:506] From /home/jupyter/work/suanming/notebooks/model_components.py:84: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1120 11:14:43.417363 139884432922368 deprecation.py:506] From /home/jupyter/work/suanming/notebooks/model_components.py:85: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "W1120 11:14:43.598902 139884432922368 deprecation.py:506] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00615546  0.016446  ]\n",
      " [ 0.00099197  0.00542042]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'tcm/sample_weights' with dtype float and shape [?]\n\t [[node tcm/sample_weights (defined at <ipython-input-11-41fa2bc6543f>:38) ]]\n\nCaused by op 'tcm/sample_weights', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-8a4adaf5482d>\", line 19, in <module>\n    dropout_keep_proba=0.5,\n  File \"<ipython-input-11-41fa2bc6543f>\", line 38, in __init__\n    self.sample_weights = tf.placeholder(shape=(None,), dtype=tf.float32, name='sample_weights')\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'tcm/sample_weights' with dtype float and shape [?]\n\t [[node tcm/sample_weights (defined at <ipython-input-11-41fa2bc6543f>:38) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'tcm/sample_weights' with dtype float and shape [?]\n\t [[{{node tcm/sample_weights}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8a4adaf5482d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'tcm/sample_weights' with dtype float and shape [?]\n\t [[node tcm/sample_weights (defined at <ipython-input-11-41fa2bc6543f>:38) ]]\n\nCaused by op 'tcm/sample_weights', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-8a4adaf5482d>\", line 19, in <module>\n    dropout_keep_proba=0.5,\n  File \"<ipython-input-11-41fa2bc6543f>\", line 38, in __init__\n    self.sample_weights = tf.placeholder(shape=(None,), dtype=tf.float32, name='sample_weights')\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'tcm/sample_weights' with dtype float and shape [?]\n\t [[node tcm/sample_weights (defined at <ipython-input-11-41fa2bc6543f>:38) ]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell\n",
    "except ImportError:\n",
    "        LSTMCell = tf.nn.rnn_cell.LSTMCell\n",
    "        LSTMStateTuple = tf.nn.rnn_cell.LSTMStateTuple\n",
    "        GRUCell = tf.nn.rnn_cell.GRUCell\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as session:\n",
    "    model = HANClassifierModel(\n",
    "      vocab_size=10,\n",
    "      embedding_size=5,\n",
    "      classes=2,\n",
    "      word_cell=GRUCell(10),\n",
    "      sentence_cell=GRUCell(10),\n",
    "      word_output_size=10,\n",
    "      sentence_output_size=10,\n",
    "      max_grad_norm=5.0,\n",
    "      dropout_keep_proba=0.5,\n",
    "    )\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    fd = {\n",
    "      model.is_training: False,\n",
    "      model.inputs: [[\n",
    "        [5, 4, 1, 0],\n",
    "        [3, 3, 6, 7],\n",
    "        [6, 7, 0, 0]\n",
    "      ],\n",
    "        [\n",
    "        [2, 2, 1, 0],\n",
    "        [3, 3, 6, 7],\n",
    "        [0, 0, 0, 0]\n",
    "      ]],\n",
    "      model.word_lengths: [\n",
    "        [3, 4, 2],\n",
    "        [3, 4, 0],\n",
    "      ],\n",
    "      model.sentence_lengths: [3, 2],\n",
    "      model.labels: [0, 1],\n",
    "    }\n",
    "\n",
    "    print(session.run(model.logits, fd))\n",
    "    session.run(model.train_op, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename='dataset/dtoc.pkl'):\n",
    "    pd_dtoc = pickle.load(open(filename, 'rb'))\n",
    "    return pd_dtoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = load_data(filename='/home/jupyter/rich/dtoc_proc.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sp_no</th>\n",
       "      <th>ep_no</th>\n",
       "      <th>start_date</th>\n",
       "      <th>diag1</th>\n",
       "      <th>diag2</th>\n",
       "      <th>diag3</th>\n",
       "      <th>diag4</th>\n",
       "      <th>diag5</th>\n",
       "      <th>diag6</th>\n",
       "      <th>...</th>\n",
       "      <th>proc12</th>\n",
       "      <th>spell_time</th>\n",
       "      <th>dest_code</th>\n",
       "      <th>adm_code</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>loe</th>\n",
       "      <th>is_oversea</th>\n",
       "      <th>los</th>\n",
       "      <th>is_dtoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M1355572</td>\n",
       "      <td>62295900</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-02-16 00:00:00</td>\n",
       "      <td>Z349</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2005-02-16 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>4232</td>\n",
       "      <td>0</td>\n",
       "      <td>4232.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M581130</td>\n",
       "      <td>62784072</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-04-11 00:00:00</td>\n",
       "      <td>Z349</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-04-11 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2303</td>\n",
       "      <td>0</td>\n",
       "      <td>2303.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M1588346</td>\n",
       "      <td>63195747</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-05 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-10-05 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1241</td>\n",
       "      <td>0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M1587381</td>\n",
       "      <td>63354756</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-03 00:00:00</td>\n",
       "      <td>O701</td>\n",
       "      <td>Z370</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-10-03 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>M1564074</td>\n",
       "      <td>63357984</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-10 00:00:00</td>\n",
       "      <td>O701</td>\n",
       "      <td>Z370</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-10-10 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1774</td>\n",
       "      <td>0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195236</td>\n",
       "      <td>5087844</td>\n",
       "      <td>4313925</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-31 00:49:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-31 00:49:00</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>30011</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195237</td>\n",
       "      <td>1253471</td>\n",
       "      <td>4313971</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-31 00:59:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-31 00:59:00</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>30011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195238</td>\n",
       "      <td>5281325</td>\n",
       "      <td>4313949</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-31 01:41:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-31 01:41:00</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>30011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195239</td>\n",
       "      <td>3034556</td>\n",
       "      <td>4314014</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-31 01:42:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-31 01:42:00</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195240</td>\n",
       "      <td>552915</td>\n",
       "      <td>4314028</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-31 01:51:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-31 01:51:00</td>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>30011</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195241 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     sp_no  ep_no          start_date diag1 diag2 diag3  \\\n",
       "0        M1355572  62295900      1 2005-02-16 00:00:00  Z349  None  None   \n",
       "1         M581130  62784072      1 2008-04-11 00:00:00  Z349  None  None   \n",
       "2        M1588346  63195747      1 2010-10-05 00:00:00  None  None  None   \n",
       "3        M1587381  63354756      1 2011-10-03 00:00:00  O701  Z370  None   \n",
       "4        M1564074  63357984      1 2011-10-10 00:00:00  O701  Z370  None   \n",
       "...           ...       ...    ...                 ...   ...   ...   ...   \n",
       "1195236   5087844   4313925      1 2018-10-31 00:49:00  None  None  None   \n",
       "1195237   1253471   4313971      1 2018-10-31 00:59:00  None  None  None   \n",
       "1195238   5281325   4313949      1 2018-10-31 01:41:00  None  None  None   \n",
       "1195239   3034556   4314014      1 2018-10-31 01:42:00  None  None  None   \n",
       "1195240    552915   4314028      1 2018-10-31 01:51:00  None  None  None   \n",
       "\n",
       "        diag4 diag5 diag6  ... proc12          spell_time dest_code adm_code  \\\n",
       "0        None  None  None  ...   None 2005-02-16 00:00:00        19       31   \n",
       "1        None  None  None  ...   None 2008-04-11 00:00:00        19       31   \n",
       "2        None  None  None  ...   None 2010-10-05 00:00:00        19       31   \n",
       "3        None  None  None  ...   None 2011-10-03 00:00:00        19       31   \n",
       "4        None  None  None  ...   None 2011-10-10 00:00:00        19       31   \n",
       "...       ...   ...   ...  ...    ...                 ...       ...      ...   \n",
       "1195236  None  None  None  ...   None 2018-10-31 00:49:00        98       21   \n",
       "1195237  None  None  None  ...   None 2018-10-31 00:59:00        98       21   \n",
       "1195238  None  None  None  ...   None 2018-10-31 01:41:00        98       21   \n",
       "1195239  None  None  None  ...   None 2018-10-31 01:42:00        98       21   \n",
       "1195240  None  None  None  ...   None 2018-10-31 01:51:00        98       21   \n",
       "\n",
       "        age gender    loe is_oversea     los is_dtoc  \n",
       "0        18      2   4232          0  4232.0     0.0  \n",
       "1        28      2   2303          0  2303.0     0.0  \n",
       "2        36      2   1241          0  1241.0     0.0  \n",
       "3        19      2    864          0   864.0     0.0  \n",
       "4        31      2   1774          0  1774.0     0.0  \n",
       "...      ..    ...    ...        ...     ...     ...  \n",
       "1195236  88      1  30011          1     NaN     0.0  \n",
       "1195237  32      2  30011          0     NaN     0.0  \n",
       "1195238  13      1  30011          0     NaN     0.0  \n",
       "1195239   0      2  30011          0     NaN     0.0  \n",
       "1195240  67      1  30011          1     NaN     0.0  \n",
       "\n",
       "[1195241 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
